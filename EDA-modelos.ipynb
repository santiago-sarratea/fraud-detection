{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando datos de una competencia proveniente de Kaggle. El proyecto busca maximizar el valor de la metrica auc-ROC para clasificar con mayor exito usuarios que han realizado fraudes con las tarjetas de credito. El dataset contiene mas de 200 columnas y 500 mil filas. Si tomamos con valor 1 el hecho de que la transaccion sea fraudulenta, existen aproximadamente un 4% de las mismas, por lo que el dataset no esta balanceado. Hay que trabajar sobre esta situacion y ver como lidiar con el desbalanceo. Existe como posibilidad e undersampling, oversampling, unca combinacion de ambos o ponerle peso distinto a las muestras con target 1 cuando se está entrenando el modelo. Se debe destacar que la naturaleza del set de prueba puede ser distinta a la del de entrenamiento por lo que un buen score en la validación del train set podria devolver valores bajos en los resultados del test set una vez subido a Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nDnUjsJdKPTU"
   },
   "outputs": [],
   "source": [
    "#Importo las librerias necesaria para el analisis de datos y los calculos matematicos\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sJCM2NNMGNA"
   },
   "source": [
    "# Descriptor de columnas:\n",
    "### Transaction Table *\n",
    "- TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n",
    "- TransactionAMT: transaction payment amount in USD\n",
    "- ProductCD: product code, the product for each transaction\n",
    "- card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n",
    "- addr: address\n",
    "- dist: distance\n",
    "- P_ and (R__) emaildomain: purchaser and recipient email domain\n",
    "- C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n",
    "- D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "- M1-M9: match, such as names on card and address, etc.\n",
    "- Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.\n",
    "\n",
    "Categorical Features:\n",
    "- ProductCD\n",
    "- card1 - card6\n",
    "- addr1, addr2\n",
    "- P_emaildomain\n",
    "- R_emaildomain\n",
    "- M1 - M9\n",
    "\n",
    "### Identity Table *\n",
    "Variables in this table are identity information – network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with transactions.\n",
    "They're collected by Vesta’s fraud protection system and digital security partners.\n",
    "(The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)\n",
    "\n",
    "Categorical Features:\n",
    "- DeviceType\n",
    "- DeviceInfo\n",
    "- id_12 - id_38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3iYJgOlSTqc-"
   },
   "outputs": [],
   "source": [
    "#Cargo el dataset de train transacciones\n",
    "train_trans = pd.read_csv('/content/gdrive/MyDrive/proyectito_santi/train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7kB7Sbpu6cDK"
   },
   "outputs": [],
   "source": [
    "#Cargo el dataset de train de ids\n",
    "train_id = pd.read_csv('/content/gdrive/MyDrive/proyectito_santi/train_identity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SRGnMa4nMPp6"
   },
   "outputs": [],
   "source": [
    "data_train=train_trans.merge(right=train_id, how='left', on='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OuuiEJG595Hg"
   },
   "outputs": [],
   "source": [
    "#Borro datsets para no gastar tanta memoria\n",
    "del train_trans\n",
    "del train_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vMcBCndgD7fA"
   },
   "outputs": [],
   "source": [
    "#Cargo el dataset de test transacciones\n",
    "test_trans = pd.read_csv('/content/gdrive/MyDrive/proyectito_santi/test_transaction.csv')\n",
    "#Cargo el dataset de test de ids\n",
    "test_id = pd.read_csv('/content/gdrive/MyDrive/proyectito_santi/test_identity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wQdFzrHQEUVu"
   },
   "outputs": [],
   "source": [
    "data_test=test_trans.merge(right=test_id, how='left', on='TransactionID')\n",
    "del test_trans\n",
    "del test_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FJqdFlRC9ry6"
   },
   "outputs": [],
   "source": [
    "old_cols= list(data_test.columns[-40:-2])\n",
    "new_cols= [x.replace('-','_') for x in old_cols]\n",
    "dic=dict(zip(old_cols, new_cols))\n",
    "data_test.rename(columns=dic, inplace= True)\n",
    "del old_cols\n",
    "del new_cols\n",
    "del dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3U1Nf6TIdb9l"
   },
   "source": [
    "#### Por inspeccion en jupyter ya se que la unica columna que no está en el test set es 'isFraud' (justamente el target) porque la idea es subir los resultados del ajuste del modelo a los test set a kaggle y ahi obtener el score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "YEUHqlPqGUvR"
   },
   "outputs": [],
   "source": [
    "#Defino la columna target para el trainset y la elimino del X_train\n",
    "X_train=data_train.iloc[:,2:]\n",
    "Y_train=data_train['isFraud']\n",
    "#Defino el X_test\n",
    "X_test=data_test.iloc[:,1:]\n",
    "#Defino las series que contienen las ids de las operaciones\n",
    "#id_train=data_train.iloc[:,0]\n",
    "id_test=data_test.iloc[:,0]\n",
    "#Elimino los datasets data_train y data_test\n",
    "del data_train\n",
    "del data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tuyRA5-USAhU"
   },
   "outputs": [],
   "source": [
    "#Quiero eliminar del X_train las columnas con mas de 60% valores nulos, pero si las elimino del X_train tambien lo hago en el X_test\n",
    "#Quiero eliminar las columnas que tengan mas de 60% de valores nulos\n",
    "has_many_nans = []\n",
    "for col in X_train.columns:\n",
    "  if X_train[col].isna().sum() > 0:\n",
    "    perc = 100*X_train[col].isna().sum()/X_train.shape[0]\n",
    "    if perc > 60:\n",
    "      has_many_nans.append(col)\n",
    "#Borro del dataset las columnas con muchos nans\n",
    "X_train.drop(columns=has_many_nans, inplace=True)\n",
    "X_test.drop(columns=has_many_nans, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "q1oSZ5kkRZGX"
   },
   "outputs": [],
   "source": [
    "def Preproc(df_merged):\n",
    "    #Voy a llenar los Nan de todas las columnas, numericas y categoricas de la misma manera\n",
    "    #A las columnas categoricas con muchos valores (id card) no voy a hacerles one hot encoding, sino que las voy a mapear a los valores mas comunes\n",
    "    for col in df_merged.columns:\n",
    "        c=df_merged[col].value_counts(normalize=True)\n",
    "        df_merged[col].fillna(value=np.random.choice(c.index, p=c.values),inplace=True)\n",
    "  #Escribo las columnas categoricas a las cuales quiero pasar pasar a numericas, donde el valor de una clase sea igual a la cantidad \n",
    "  #de veces que aparece esa clase dentro de la columna categorica. De esa manera si un mismo id de tarjeta aparece varias veces tendra un orden\n",
    "  #en importancia mayor que otras que no\n",
    "    cats=['card1','card2','card3','card5','addr1','addr2','P_emaildomain']\n",
    "    for col in cats:\n",
    "        df_merged[col]=df_merged[col].map(df_merged[col].value_counts(normalize=True))\n",
    "  #Defino a las columnas a las cuales voy a hacerles one hot encoding (uso getdummies)\n",
    "    true_cats = ['ProductCD', 'card6', 'card4'] + ['M'+str(i) for i in range(1,10)]\n",
    "  #Hago el hotencoding con el metodo get_dummies, en este caso me parece mas practico\n",
    "    df_merged = pd.get_dummies(df_merged, prefix=true_cats, columns = true_cats, drop_first=True)\n",
    "  #Ahora voya  usar Standar Scaler para escalear los datos\n",
    "    scaler = StandardScaler()\n",
    "    cols_to_transform=[col for col in df_merged.columns if df_merged[col].dtype != 'category']\n",
    "    cols_not_to_transform=[col for col in df_merged.columns if df_merged[col].dtype == 'category']\n",
    "    scaled_values= scaler.fit_transform(df_merged.loc[:,cols_to_transform])\n",
    "    scaled_values = pd.DataFrame(scaled_values, columns=cols_to_transform)\n",
    "    df_merged = pd.concat([df_merged[cols_not_to_transform], scaled_values],axis=1)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JPY9V67cxV9Z"
   },
   "outputs": [],
   "source": [
    "#Defino los datasets de entranamiento y prueba\n",
    "X_train=Preproc(X_train)\n",
    "X_test=Preproc(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wk0L-st3_d17"
   },
   "outputs": [],
   "source": [
    "#Importo paquetes de sklearn, xgboost y imblearn para los modelos, el pipeline y para lidiar con el desbalanceo\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qy5qPefWPtBT"
   },
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLBm7SvuP7DK"
   },
   "source": [
    "## Opcion 1: Undersampleo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Jn-jYxXPsDR"
   },
   "outputs": [],
   "source": [
    "#Ahora quiero undersamplear mi dataset\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61Mz_SJ6T96X"
   },
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy = 0.25, random_state = 42)\n",
    "X_train_us, Y_train_us = rus.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7wI5b6DUbrP"
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state = 42)\n",
    "X_train_os, Y_train_os = ros.fit_resample(X_train_us, Y_train_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2fNQfTTQPtc"
   },
   "outputs": [],
   "source": [
    "del X_train_us\n",
    "del Y_train_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KwKmEpfU2Fj",
    "outputId": "34e66d5a-0702-4ffc-ee2b-a25d94739e45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165304,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_os.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELz4TOL3Vcnp"
   },
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kB-6nuIyVlMu"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ct7T8fiDVzJB"
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state = 5)\n",
    "# Voy a probar con y sin undersampleo\n",
    "params={'max_depth':[5,7,10], 'min_samples_split':[1000, 2500, 3500]}\n",
    "grid_forest = GridSearchCV(estimator= forest, param_grid= params, scoring='roc_auc', n_jobs= -1, cv= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqnLGof4W7HJ",
    "outputId": "515838fa-2aed-4d70-8524-89a37b07d995"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_split=1000, random_state=5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_forest.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Th_xk2QoghHm"
   },
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(max_depth=10, min_samples_split=1000, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXS8Yb7J-A8Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gIzfMLkEhxKM"
   },
   "outputs": [],
   "source": [
    "scores=cross_val_score(rf, X_train_os, Y_train_os, cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaIVAGHjix05",
    "outputId": "574eaa1b-3531-47e4-ee33-2d5e3d1be43c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88156354 0.88116979 0.88242381 0.88179672 0.88284149]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVGLwdh7mU2Z",
    "outputId": "a02a172f-d01f-4e04-f920-c28ca0f68df2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_split=1000, random_state=5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_os,Y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFhN1iRljtdh"
   },
   "outputs": [],
   "source": [
    "#En el test set no aparece la opcion credito-debito asi que la agrego para que hayan las mismas columnas en el train y test set\n",
    "X_test.insert(218, 'card6_debit or credit', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RS11uzK7l8sJ"
   },
   "outputs": [],
   "source": [
    "test_predict = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQGMA-lCmNFw"
   },
   "outputs": [],
   "source": [
    "test_pred_df = pd.concat([id_test, pd.DataFrame({'isFraud': test_predict[:,1]})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gEIJxTOSjZ4v"
   },
   "outputs": [],
   "source": [
    "test_pred_df.to_csv('/content/gdrive/MyDrive/proyectito_santi/random_forest_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BPp3Xr6OY2K"
   },
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mi4QrhRsak5F"
   },
   "source": [
    "#### Hago una prueba sin tunear hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bv42nZHAOrOm"
   },
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(silent=False, \n",
    "                      scale_pos_weight=1,\n",
    "                      learning_rate=0.01,  \n",
    "                      colsample_bytree = 0.4,\n",
    "                      subsample = 0.8,\n",
    "                      objective='binary:logistic', \n",
    "                      n_estimators=100, \n",
    "                      reg_alpha = 0.3,\n",
    "                      max_depth=4, \n",
    "                      gamma=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtCjN-dzOrU9"
   },
   "outputs": [],
   "source": [
    "scores=cross_val_score(XGB, X_train_os, Y_train_os, cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jD8StANTcQSm",
    "outputId": "9044604e-89b1-43e7-b2b3-3a5336d029ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86497508 0.86633865 0.86675269 0.86595652 0.86673073]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBPSbSeQOrRx",
    "outputId": "63915d75-4fdd-4423-8ed9-0e14b619708b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(colsample_bytree=0.4, gamma=10, learning_rate=0.01, max_depth=4,\n",
       "              reg_alpha=0.3, silent=False, subsample=0.8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB.fit(X_train_os,Y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ERHXiaU3dBxw"
   },
   "outputs": [],
   "source": [
    "f_import=pd.DataFrame({'Features':X_train_os.columns, 'Importance':XGB.feature_importances_})\n",
    "f_import= f_import.sort_values('Importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "bgVrct0xdiCW",
    "outputId": "84ce3ffc-1993-4e95-c8c1-6c62b85b6dbd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f01dbb01-841d-4952-bf8c-14a75f827e80\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>V74</td>\n",
       "      <td>0.073769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>V33</td>\n",
       "      <td>0.060591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C8</td>\n",
       "      <td>0.055471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>V90</td>\n",
       "      <td>0.044289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>V73</td>\n",
       "      <td>0.043152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>V295</td>\n",
       "      <td>0.029528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>V69</td>\n",
       "      <td>0.029093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C14</td>\n",
       "      <td>0.028706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C4</td>\n",
       "      <td>0.027998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C5</td>\n",
       "      <td>0.026255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>V308</td>\n",
       "      <td>0.025127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>V317</td>\n",
       "      <td>0.024751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>V294</td>\n",
       "      <td>0.021505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C1</td>\n",
       "      <td>0.019683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>V280</td>\n",
       "      <td>0.018977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>V29</td>\n",
       "      <td>0.018813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C10</td>\n",
       "      <td>0.018651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>V94</td>\n",
       "      <td>0.018645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>V34</td>\n",
       "      <td>0.017241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C2</td>\n",
       "      <td>0.015405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f01dbb01-841d-4952-bf8c-14a75f827e80')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f01dbb01-841d-4952-bf8c-14a75f827e80 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f01dbb01-841d-4952-bf8c-14a75f827e80');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    Features  Importance\n",
       "105      V74    0.073769\n",
       "64       V33    0.060591\n",
       "17        C8    0.055471\n",
       "121      V90    0.044289\n",
       "104      V73    0.043152\n",
       "185     V295    0.029528\n",
       "100      V69    0.029093\n",
       "23       C14    0.028706\n",
       "13        C4    0.027998\n",
       "14        C5    0.026255\n",
       "198     V308    0.025127\n",
       "207     V317    0.024751\n",
       "184     V294    0.021505\n",
       "10        C1    0.019683\n",
       "170     V280    0.018977\n",
       "60       V29    0.018813\n",
       "19       C10    0.018651\n",
       "125      V94    0.018645\n",
       "65       V34    0.017241\n",
       "11        C2    0.015405"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Columnas con mas importancia para el modelo sin tunear hiperparametros\n",
    "f_import.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6UbFCMSOrXi"
   },
   "outputs": [],
   "source": [
    "#X_test.insert(218, 'card6_debit or credit', 0)\n",
    "test_predict = XGB.predict_proba(X_test)\n",
    "test_pred_df = pd.concat([id_test, pd.DataFrame({'isFraud': test_predict[:,1]})], axis=1)\n",
    "test_pred_df.to_csv('XGB_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hjbmm-C7gU2c"
   },
   "source": [
    "Los resultados no fueron mejores que son el randon forest. Voy a intentar tunear hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPVjEvBAiUcl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYXm-O1_OraW"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"colsample_bytree\": uniform(0.3, 0.7),\n",
    "    \"gamma\": uniform(0, 0.5),\n",
    "    \"learning_rate\": uniform(0.01, 0.3), # default 0.1 \n",
    "    \"max_depth\": randint(2, 6), # default 3\n",
    "    \"n_estimators\": randint(100, 150), # default 100\n",
    "    \"subsample\": uniform(0.4, 0.9)\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(XGBClassifier(random_satate=5), param_distributions=params, random_state=42, n_iter=200, cv=3, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "search.fit(X_train_os, Y_train_os)\n",
    "\n",
    "report_best_scores(search.cv_results_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lS9Yuy38g1V9",
    "outputId": "897f543c-7110-4c66-b70e-5d1d01d111e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(colsample_bytree=0.7515723534213954, gamma=0.3344620298315498,\n",
       "              learning_rate=0.26925026952157094, max_depth=5, n_estimators=147,\n",
       "              random_satate=5, subsample=0.6526951261967702)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AddEFXdtIfHn"
   },
   "outputs": [],
   "source": [
    "best_xgb=XGBClassifier(colsample_bytree=0.7515723534213954, gamma=0.3344620298315498,\n",
    "              learning_rate=0.26925026952157094, max_depth=5, n_estimators=147,\n",
    "              random_satate=5, subsample=0.6526951261967702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMtHeZkvI6ut"
   },
   "outputs": [],
   "source": [
    "scores=cross_val_score(best_xgb, X_train_os, Y_train_os, cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GAs-4Hu2JUtH",
    "outputId": "2a27893c-f4bf-4838-ee99-e1f30b510dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95252963 0.95238314 0.95734399 0.95501244 0.95865854]\n"
     ]
    }
   ],
   "source": [
    "print(scores) #Valores de la validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5esa2b3OIYQ"
   },
   "outputs": [],
   "source": [
    "#X_test.insert(218, 'card6_debit or credit', 0)\n",
    "best_xgb.fit(X_train_os,Y_train_os)\n",
    "test_predict = best_xgb.predict_proba(X_test)\n",
    "test_pred_df = pd.concat([id_test, pd.DataFrame({'isFraud': test_predict[:,1]})], axis=1)\n",
    "test_pred_df.to_csv('best_XGB_predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se observa que el mejor modelo con la ingenieria de features utilizada es el random forest, aunque para valores de validacion el xgboost ha dado mejores resultados. Esto puede deberse a que la forma de hacer ingenieria de features en el conjunto de entrenamiento no es la misma que en el conjunto de prueba provisto por Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"score-fraude.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EDA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
